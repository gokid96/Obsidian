## QLoRA Fine-tuning íŠœí† ë¦¬ì–¼ (Unsloth ë²„ì „)

## ê°œìš”

|í•­ëª©|ë‚´ìš©|
|---|---|
|ëª©í‘œ|Llama-3.1-8Bë¥¼ KorQuAD ë°ì´í„°ë¡œ fine-tuning|
|ë°©ì‹|QLoRA (Unsloth ì‚¬ì „ ì–‘ìí™”)|
|íŠ¹ì§•|2ë°° ë¹ ë¦„, 70% VRAM ì ˆì•½, ì½”ë“œ ê°„ê²°|
|í™˜ê²½|Ubuntu + RTX 5080 (16GB VRAM)|

---

## Self vs Unsloth ë¹„êµ

|í•­ëª©|Self ë²„ì „|Unsloth ë²„ì „|
|---|---|---|
|ëª¨ë¸|Llama-2-7B|Llama-3.1-8B|
|ì–‘ìí™”|ì§ì ‘ ì„¤ì • (BitsAndBytesConfig)|ì‚¬ì „ ì–‘ìí™” ëª¨ë¸ ì‚¬ìš©|
|ì†ë„|1x|2x|
|VRAM|~7GB|~5GB|
|ì½”ë“œëŸ‰|ë§ìŒ|ê°„ê²°|

---

## íŒŒì¼ êµ¬ì¡°
```
~/ai-projects/llama2-korquad/
â”œâ”€â”€ KorQuAD_v1.0_dev.json          # ì›ë³¸ ë°ì´í„°
â”œâ”€â”€ prepare_tutorial_data.py       # ë°ì´í„° ì¤€ë¹„ (ê³µìš©)
â”œâ”€â”€ korquad_tutorial.json          # í•™ìŠµ ë°ì´í„° (20ê°œ)
â”œâ”€â”€ unsloth_train_qlora.py         # í•™ìŠµ (Unsloth ë²„ì „)
â”œâ”€â”€ unsloth_train_qlora_test.py    # í…ŒìŠ¤íŠ¸
â””â”€â”€ llama3-korquad-qlora/
    â””â”€â”€ final/
        â””â”€â”€ adapter_model.safetensors
```

---

## í™˜ê²½ ì„¤ì •
```bash
source ~/ai-projects/venv/bin/activate

# Unsloth ì„¤ì¹˜
pip install unsloth
```

---

## 1. í•™ìŠµ (unsloth_train_qlora.py)
```python
"""
Llama-3.1 QLoRA Fine-tuning with Unsloth
"""
from unsloth import FastLanguageModel
from datasets import load_dataset
from trl import SFTTrainer, SFTConfig

# ============================================
# ì„¤ì •
# ============================================
MODEL_NAME = "unsloth/Meta-Llama-3.1-8B-bnb-4bit"
OUTPUT_DIR = "./llama3-korquad-qlora"

# ============================================
# ëª¨ë¸ + í† í¬ë‚˜ì´ì € ë¡œë“œ (Unsloth)
# ============================================
print("ğŸ¤– ëª¨ë¸ ë¡œë”©...")
model, tokenizer = FastLanguageModel.from_pretrained(
    model_name=MODEL_NAME,
    max_seq_length=2048,
    load_in_4bit=True,
)

# ============================================
# LoRA ì„¤ì • (Unsloth)
# ============================================
print("ğŸ”§ LoRA ì„¤ì •...")
model = FastLanguageModel.get_peft_model(
    model,
    r=16,
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj", 
                    "gate_proj", "up_proj", "down_proj"],
    lora_alpha=16,
    lora_dropout=0,
    bias="none",
    use_gradient_checkpointing="unsloth",
)

print("ğŸ“Š í•™ìŠµ íŒŒë¼ë¯¸í„°:")
model.print_trainable_parameters()

# ============================================
# ë°ì´í„°ì…‹ ë¡œë“œ
# ============================================
print("ğŸ“¦ ë°ì´í„°ì…‹ ë¡œë”©...")
dataset = load_dataset("json", data_files="korquad_tutorial.json", split="train")
print(f"  ë°ì´í„° ìˆ˜: {len(dataset)}")

# ============================================
# SFTConfig
# ============================================
sft_config = SFTConfig(
    output_dir=OUTPUT_DIR,
    num_train_epochs=100,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=4,
    learning_rate=2e-4,
    fp16=True,
    logging_steps=10,
    save_strategy="epoch",
    optim="adamw_8bit",
    warmup_ratio=0.03,
    lr_scheduler_type="cosine",
    report_to="none",
    max_seq_length=2048,
    dataset_text_field="text",
)

# ============================================
# SFTTrainer
# ============================================
print("ğŸš€ í•™ìŠµ ì‹œì‘!")
trainer = SFTTrainer(
    model=model,
    args=sft_config,
    train_dataset=dataset,
    processing_class=tokenizer,
)

trainer.train()

# ============================================
# ì €ì¥
# ============================================
print("ğŸ’¾ ëª¨ë¸ ì €ì¥...")
trainer.save_model(f"{OUTPUT_DIR}/final")
tokenizer.save_pretrained(f"{OUTPUT_DIR}/final")
print(f"âœ… ì™„ë£Œ! ì €ì¥ ìœ„ì¹˜: {OUTPUT_DIR}/final")
```

---

## 2. í…ŒìŠ¤íŠ¸ (unsloth_train_qlora_test.py)
```python
from unsloth import FastLanguageModel

print("ğŸ¤– ëª¨ë¸ ë¡œë”©...")
model, tokenizer = FastLanguageModel.from_pretrained(
    model_name="./llama3-korquad-qlora/final",
    max_seq_length=2048,
    load_in_4bit=True,
)
FastLanguageModel.for_inference(model)

prompt_template = "Below is an instruction that describes a task. Write a response that appropriately completes the request. ### Instruction: %s ### Response: "

def gen(question):
    prompt = prompt_template % question
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
    outputs = model.generate(**inputs, max_new_tokens=128, do_sample=False)
    return tokenizer.decode(outputs[0], skip_special_tokens=True).replace(prompt, "")

questions = [
    ("ì„ì¢…ì„ì´ ì—¬ì˜ë„ ë†ë¯¼ í­ë ¥ ì‹œìœ„ë¥¼ ì£¼ë„í•œ í˜ì˜ë¡œ ì§€ëª…ìˆ˜ë°° ëœ ë‚ ì€?", "1989ë…„ 2ì›” 15ì¼"),
    ("1989ë…„ 6ì›” 30ì¼ í‰ì–‘ì¶•ì „ì— ëŒ€í‘œë¡œ íŒŒê²¬ ëœ ì¸ë¬¼ì€?", "ì„ìˆ˜ê²½"),
    ("ì„ì¢…ì„ì´ ì—¬ì˜ë„ ë†ë¯¼ í­ë ¥ ì‹œìœ„ë¥¼ ì£¼ë„í•œ í˜ì˜ë¡œ ì§€ëª…ìˆ˜ë°°ëœ ì—°ë„ëŠ”?", "1989ë…„"),
    ("ì„ì¢…ì„ì„ ê²€ê±°í•œ ì¥ì†ŒëŠ” ê²½í¬ëŒ€ ë‚´ ì–´ë””ì¸ê°€?", "í•™ìƒíšŒê´€ ê±´ë¬¼ ê³„ë‹¨"),
    ("ì„ì¢…ì„ì´ ì¡°ì‚¬ë¥¼ ë°›ì€ ë’¤ ì¸ê³„ëœ ê³³ì€ ì–´ë”˜ê°€?", "ì„œìš¸ì§€ë°©ê²½ì°°ì²­ ê³µì•ˆë¶„ì‹¤"),
]

print("\n" + "="*60)
print("ğŸ“ í…ŒìŠ¤íŠ¸ (5ê°œ ìƒ˜í”Œ)")
print("="*60)

correct = 0
for q, answer in questions:
    result = gen(q)
    match = "âœ…" if answer in result else "âŒ"
    if answer in result:
        correct += 1
    print(f"\nì§ˆë¬¸: {q[:50]}...")
    print(f"ì •ë‹µ: {answer}")
    print(f"ìƒì„±: {result[:50]}")
    print(f"ì¼ì¹˜: {match}")

print(f"\nì •í™•ë„: {correct}/{len(questions)}")
```

---

## ì‹¤í–‰
```bash
cd ~/ai-projects/llama2-korquad
source ~/ai-projects/venv/bin/activate

python prepare_tutorial_data.py      # ë°ì´í„° ì¤€ë¹„ (ì´ë¯¸ í–ˆìœ¼ë©´ ìƒëµ)
python unsloth_train_qlora.py        # í•™ìŠµ
python unsloth_train_qlora_test.py   # í…ŒìŠ¤íŠ¸
```

---

## Unslothê°€ ìë™ìœ¼ë¡œ í•´ì£¼ëŠ” ê²ƒ

|í•­ëª©|Self ë²„ì „|Unsloth ë²„ì „|
|---|---|---|
|BitsAndBytesConfig|ì§ì ‘ ì„¤ì •|ë‚´ë¶€ ì²˜ë¦¬|
|prepare_model_for_kbit_training()|ì§ì ‘ í˜¸ì¶œ|ë‚´ë¶€ ì²˜ë¦¬|
|gradient_checkpointing_enable()|ì§ì ‘ í˜¸ì¶œ|`use_gradient_checkpointing="unsloth"`|
|LoraConfig|ì§ì ‘ ì„¤ì •|`FastLanguageModel.get_peft_model()`|

---

## í•µì‹¬ í¬ì¸íŠ¸

1. **ì‚¬ì „ ì–‘ìí™” ëª¨ë¸** â€” `unsloth/xxx-bnb-4bit` ë‹¤ìš´ë°›ìœ¼ë©´ ë°”ë¡œ ì‚¬ìš©
2. **FastLanguageModel** â€” ëª¨ë¸ + í† í¬ë‚˜ì´ì € + LoRA í•œ ë²ˆì— ì²˜ë¦¬
3. **for_inference()** â€” ì¶”ë¡  ì‹œ 2ë°° ì†ë„ í–¥ìƒ
4. **2025ë…„ í‘œì¤€** â€” ì‹¤ë¬´ì—ì„œ ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” ë°©ì‹