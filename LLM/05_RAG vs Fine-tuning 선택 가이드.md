## 핵심 차이

| 구분 | Fine-tuning | RAG |
|------|-------------|-----|
| 방식 | 모델 자체를 바꿈 | 검색 + LLM 조합 |
| 비용 | 높음 (GPU, 시간) | 낮음 (API 비용만) |
| 유지보수 | 어려움 (재학습 필요) | 쉬움 (문서만 업데이트) |
| 데이터 업데이트 | 다시 학습해야 함 | 즉시 반영 가능 |

## 비유
```
Fine-tuning: 사람 머릿속에 지식을 외우게 함
RAG: 사람에게 참고서를 주고 찾아보게 함
```

---

## 언제 뭘 써야 하나?

### Fine-tuning이 필요한 경우

| 상황 | 예시 |
|------|------|
| 말투/스타일 바꾸고 싶을 때 | 반말, 존댓말, 법률 문서체 |
| 특수 형식 출력 필요 | 특정 JSON 구조, 코드 스타일 |
| 도메인 전문 용어 학습 | 의료, 법률, 회사 내부 용어 |
| 모델 행동 자체를 바꿀 때 | 특정 주제 거부, 응답 방식 변경 |

### RAG가 적합한 경우

| 상황 | 예시 |
|------|------|
| 회사 내부 문서 기반 답변 | 사내 위키, 매뉴얼 |
| 최신 정보 반영 필요 | 뉴스, 제품 정보, 가격 |
| 데이터가 자주 바뀜 | FAQ, 정책 문서 |
| 출처 명시가 필요함 | "이 답변은 OO문서 기반" |
| 빠르게 구현해야 함 | PoC, MVP |

---

## 선택 플로우차트
```
"우리 회사 데이터로 LLM 쓰고 싶다"
        ↓
데이터가 자주 바뀌나?
   ├── YES → RAG
   └── NO ↓

모델의 말투/스타일을 바꿔야 하나?
   ├── YES → Fine-tuning
   └── NO ↓

출처 표시가 필요한가?
   ├── YES → RAG
   └── NO → 둘 다 가능 (RAG 먼저 시도)
```

---

## 비용 비교

| 항목 | Fine-tuning | RAG |
|------|-------------|-----|
| 초기 구축 | 높음 (GPU, 데이터 준비) | 낮음 |
| 운영 비용 | 낮음 (자체 모델) | API 호출당 비용 |
| 업데이트 비용 | 높음 (재학습) | 낮음 (문서 추가만) |

---

## 현실적인 조합

실무에서는 둘 다 조합해서 쓰기도 함:
```
Fine-tuning → 말투, 형식 학습
    +
RAG → 최신 데이터 검색

= "우리 회사 스타일로 + 최신 문서 기반 답변"
```

---

## 실무 선택 요약

| 목적 | 선택 |
|------|------|
| 지식/정보 추가 | RAG |
| 행동/스타일 변경 | Fine-tuning |
| 빠른 구현 | RAG |
| 오프라인/보안 중요 | Fine-tuning (로컬 모델) |
| 잘 모르겠다 | RAG 먼저 시도 |

---

## 한 줄 요약

> "지식 추가는 RAG, 행동 변경은 Fine-tuning"
> "대부분의 경우 RAG로 충분하다"
