## LLM 개념 기초

### LLM이란

- Large Language Model, 대규모 언어 모델
- 수십억~수천억 개 파라미터로 텍스트의 다음 단어를 예측하도록 학습
- GPT, Claude, Llama 등이 대표적

### 토큰화 (Tokenization)

- 텍스트를 모델이 처리할 수 있는 숫자(토큰 ID)로 변환
- "안녕하세요" → [12345, 67890] 같은 식
- BPE(Byte Pair Encoding)가 가장 많이 쓰이는 알고리즘
- 토큰 ≠ 글자, 토큰 ≠ 단어 (그 중간 어딘가)

### In-context Learning

- 파인튜닝 없이 프롬프트에 예시를 넣어서 모델이 패턴을 파악하게 하는 방식
- Zero-shot: 예시 없이 바로 질문
- Few-shot: 예시 몇 개 보여주고 질문
- 모델 가중치는 변하지 않음

### Temperature

- 0에 가까울수록: 일관되고 예측 가능한 출력 (사실 기반 작업)
- 1에 가까울수록: 다양하고 창의적인 출력 (창작 작업)
- 실무에서는 보통 0.0~0.7 사이 사용

---

## 파인튜닝

### PEFT (Parameter-Efficient Fine-Tuning)

- 전체 파라미터 다 학습하면 비용/시간 너무 큼
- 일부 파라미터만 학습해서 효율화
- 종류: LoRA, Prefix-Tuning, P-Tuning, Prompt Tuning
- 실무에서는 LoRA/QLoRA가 사실상 표준

### LoRA (Low-Rank Adaptation)

- 기존 가중치는 freeze하고, 작은 행렬(A, B)만 추가로 학습
- 원리: W' = W + BA (rank가 낮은 행렬 두 개 곱)
- 장점: VRAM 적게 먹음, 학습 빠름, 원본 모델 보존
- 7B 모델 기준 약 16GB VRAM 필요

### QLoRA (Quantized LoRA)

- LoRA + 4bit 양자화
- 7B 모델 기준 약 6GB VRAM으로 가능
- RTX 3090/4090, Colab에서도 돌아감
- 성능은 LoRA의 96~99% 수준

### 파인튜닝 방식 비교

|방식|설명|사용 시점|
|---|---|---|
|SFT|(질문, 답변) 쌍으로 학습|대화 형식 가르칠 때|
|RLHF|사람 피드백으로 강화학습|최고 품질 원할 때|
|DPO|RLHF 간소화, Reward Model 없이|리소스 제한될 때|

### 실무 선택 기준

|상황|선택|
|---|---|
|개인/소규모 팀|QLoRA + SFT|
|회사에서 A100 있음|LoRA + SFT|
|빅테크급 리소스|Full Fine-tuning + RLHF|

---

## RAG (Retrieval-Augmented Generation)

### 임베딩 (Embedding)

- 텍스트를 고차원 벡터(숫자 배열)로 변환
- 의미가 비슷한 텍스트는 벡터도 가까움
- 코사인 유사도로 비교
- OpenAI `text-embedding-3-small` 등 사용

### 임베딩 활용

- 시맨틱 검색: 키워드가 아닌 의미로 검색
- 문서 분류: 벡터 거리로 카테고리 분류
- 클러스터링: 비슷한 문서 그룹화
- 추천: 유사 콘텐츠 찾기

### RAG 파이프라인

```
문서 → 청크 분할 → 임베딩 → 벡터DB 저장
         ↓
질문 → 임베딩 → 유사 청크 검색 → LLM에 컨텍스트로 전달 → 답변
```

### RAG vs 파인튜닝

|기준|RAG|파인튜닝|
|---|---|---|
|최신 정보|O|X|
|출처 명시|O|어려움|
|구현 난이도|낮음|높음|
|비용|낮음|높음|
|모델 행동 변경|X|O|

---

## 에이전트

### Function Calling

- LLM이 직접 함수를 실행하는 게 아니라, "이 함수를 이 파라미터로 호출해"라고 JSON 출력
- 개발자가 실제 함수 실행 후 결과를 다시 LLM에 전달

```
사용자: "서울 날씨 알려줘"
    ↓
LLM: {"function": "get_weather", "params": {"city": "서울"}}
    ↓
개발자: 실제 API 호출 → 결과 받음
    ↓
LLM: "서울은 현재 맑고 15도입니다"
```

- 에이전트의 기초: 검색, DB 조회, 외부 API 연동 등 가능

---

## 실무 판단

### 프롬프트 / RAG / 파인튜닝 선택 기준

|문제 상황|해결책|
|---|---|
|답변 형식이 안 맞음|프롬프트 개선|
|최신/내부 정보 필요|RAG|
|특정 도메인 지식 필요|RAG 먼저, 안 되면 파인튜닝|
|모델 톤/스타일 바꾸고 싶음|파인튜닝|
|할루시네이션 줄이고 싶음|RAG + 프롬프트|

### 순서

```
프롬프트 엔지니어링 → RAG → 파인튜닝
(비용 낮은 순서대로 시도)
```

### Chain-of-Thought (CoT)

- "단계별로 생각해봐" 추가하면 추론 성능 향상
- 수학, 논리 문제에서 특히 효과적
- Zero-shot CoT: "Let's think step by step"만 붙여도 효과 있음

### Moderation API

- 입력/출력에서 유해 콘텐츠 필터링
- 욕설, 폭력, 성적 콘텐츠, 자해 등 카테고리별 점수 반환
- 서비스 출시 전 필수로 검토해야 할 부분

---
